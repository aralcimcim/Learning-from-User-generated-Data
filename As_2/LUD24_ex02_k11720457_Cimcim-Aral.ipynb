{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*UE Learning from User-generated Data, CP MMS, JKU Linz 2024*\n",
    "# Exercise 2: Collaborative Filtering + Implicit Feedback\n",
    "\n",
    "In this exercise we create our first proper recommender: Item-based K-Nearest Neighbours (ItemKNN) on implicit feedback from the family of Collaborative Filtering algorithms. Please refer to the slides and the recording of the relevant UE session published on Moodle if you have any problems. Feel free to ask questions in the Discussions forum.\n",
    "\n",
    "The assignment submission deadline is 03.04.2024 23:59.\n",
    "\n",
    "Make sure to rename the notebook according to the convention:\\\n",
    "LUD24_ex02_k<font color='red'>\\<Matr. Number\\></font>_<font color='red'>\\<Surname-Name\\></font>.ipynb\n",
    "\n",
    "for example:\n",
    "\n",
    "LUD24_ex02_k000007_Bond-James.ipynb\n",
    "\n",
    "## Implementation\n",
    "In this exercise you are required to write three functions each calling the previous. Every function will be graded separately. Insert your implementations into the templates provided. Please don't change the templates even if they are not pretty. Don't forget to test your implementation for correctness and efficiency (a single run of any function should not take more than 2 minutes).\n",
    "\n",
    "Please only use libraries already imported in the notebook. **Feel free to experiment with the notebook, but clean it up before submitting.**\n",
    "    \n",
    "The asserts present are meant for the LFM-tiny dataset from the previous exercise.\n",
    "\n",
    "## Item-Based Collaborative Filtering\n",
    "The idea of Item-Based Collaborative Filtering is to estimate if a user **u** is going to like item **i** through checking how similar this item is to the items already consumed (and rated) by the user. One way to calculate the estimation is a sum of ratings given by **u** to the consumed items weighted with their respective similarities to the item **i**. Please note, that from all items consumed by the user we only consider top **N** items most similar to item **i**.\n",
    "\n",
    "In case of implicit feedback (which we deal with in this exercise), all \"ratings\" are either 0 or 1. Therefore, we combine our score from the similarities themselves. In this exercise we take the **average** of similarities to top **N** (or less if not enough neighbors was found) most similar to **i** items. Also note that we don't have to account for biases and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction Matrix\n",
    "\n",
    "In this exercise we work with the same format of interaction matrices as in the Exercise 1 (default settings) and the same data (LFM-tiny). Find a way to use the matrix in this notebook (e.g. copy your implementation of inter_matr_binary here and create the matrix anew)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter_matr_implicit(users: pd.DataFrame,\n",
    "                        items: pd.DataFrame,\n",
    "                        interactions: pd.DataFrame,\n",
    "                        dataset_name: str,\n",
    "                        threshold=1) -> np.ndarray:\n",
    "    '''\n",
    "    users - pandas Dataframe, use it as loaded from the dataset;\n",
    "    items - pandas Dataframe, use it as loaded from the dataset;\n",
    "    interactions - pandas Dataframe, use it as loaded from the dataset;\n",
    "    dataset_name - string out of [\"lfm-ismir\", \"ml-1m\"], name of the dataset, used in case there are differences in the column names of the data frames;\n",
    "    threshold - int > 0, criteria of a valid interaction\n",
    "\n",
    "    returns - 2D np.ndarray, rows - users, columns - items;\n",
    "    '''\n",
    "\n",
    "    res = None\n",
    "\n",
    "    # getting number of users and items from the respective files to be on the safe side\n",
    "    n_users = len(users.index)\n",
    "    n_items = len(items.index)\n",
    "\n",
    "    # preparing the output matrix\n",
    "    res = np.zeros([n_users, n_items], dtype=np.int8)\n",
    "\n",
    "    # for every interaction assign 1 to the respective element of the matrix\n",
    "    if dataset_name == 'lfm-tiny':\n",
    "        inter_column_name = 'listening_events'\n",
    "\n",
    "    row = interactions[\"user_id\"].to_numpy()\n",
    "    col = interactions[\"item_id\"].to_numpy()\n",
    "\n",
    "    data = interactions[inter_column_name].to_numpy()\n",
    "    data[data < threshold] = 0\n",
    "    data[data >= threshold] = 1\n",
    "\n",
    "    res[row, col] = data\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(dataset, file):\n",
    "    return pd.read_csv(dataset + '/' + dataset + '.' + file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use LFM-Tiny dataset from exercise 1\n",
    "users = read('lfm-tiny', 'user')\n",
    "items = read('lfm-tiny', 'item')\n",
    "interactions = read('lfm-tiny', 'inter')\n",
    "\n",
    "_interaction_matrix = inter_matr_implicit(users, items, interactions, \"lfm-tiny\", 1)\n",
    "_interaction_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>TASK 1/3</font>: Get item similarities (3 points)\n",
    "This is a helper function to be later used for user-item score estimation.\n",
    "The function should take three arguments: a similarity measure (Jaccard distance in our case, see below), a binary interaction_matrix-like numpy array **inter** and a plane binary vector corresponding to an item **target_vec**. You can expect that the length of the vector corresponds to the number of users in the matrix **inter** (first parameter).\n",
    "\n",
    "*the vector can be just a slice of the interaction matrix, see asserts*\n",
    "\n",
    "Expected output: array of similarities between every item in **inter** and the vector **target_vec**. The similarities need to be placed in the order the items appear in the matrix **inter**.\n",
    "\n",
    "Example: **inter** is a 7 by 3 matrix, containing information about 3 items and 7 users (can be expressed through item vectors as [it1; it2; it3]). **target_vec** is a vector of length 7 (assuming it tells us about interactions between the item and the same 7 users). The expected output is an array of length 3:\\\n",
    "[*sim*(it1, target_vec), *sim*(it2, target_vec), *sim*(it3, target_vec)]\n",
    "\n",
    "**Similarity:** use jaccard score as the similarity measure. Please implement it yourself, don't use any external libraries;\\\n",
    "If $a$ and $b$ are two items, let's define $U(a)$ as the set of users, interacted with the item $a$ (same for $b$). $|U(a)|$ corresponds to the number of users interacted with the item $a$ (cardinality of the set). Then Jaccard similarity score between the two items is defined as:\\\n",
    "\\\n",
    "$JaccardScore(a,b) = \\frac{|U(a) \\wedge U(b)|}{|U(a) \\vee U(b)|}$\n",
    "\n",
    "In words: Jaccard Score is the number of users interacted with both items divided by the number of users interacted with at least one of them.\n",
    "\n",
    "Use the cell below to define the similarity as a helper function, please don't change the parameters, name or output format.\n",
    "\n",
    "<b>Tip:</b> The item vectors are on the axis=1 in the matrix.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_score(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    a, b: - vectors of the same length corresponding to the two items\n",
    "\n",
    "    returns: float - jaccard similarity score for a and b\n",
    "    \"\"\"\n",
    "    score = None\n",
    "\n",
    "    a_and_b = np.logical_and(a, b)\n",
    "    a_or_b = np.logical_or(a, b)\n",
    "    score = np.sum(a_and_b) / np.sum(a_or_b)\n",
    "\n",
    "    return float(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sim_scores(similarity_measure: Callable[[int, int], float],\n",
    "                         inter: np.ndarray,\n",
    "                         target_vec: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    similarity_measure: Callable - function that measures similarity, use your jaccard_score function from above\n",
    "    inter: np.ndarray - interaction matrix - calculate similarity between each item and the target item (see below)\n",
    "    target_vec: np.ndarray - target item vector\n",
    "    \n",
    "    returns: np.ndarray - similarities between every item from <inter> and <target_vec> in the respective order\n",
    "    \"\"\"\n",
    "\n",
    "    item_similarities = []\n",
    "    for item in range(inter.shape[1]):\n",
    "        item_similarities.append(similarity_measure(inter[:, item], target_vec))\n",
    "\n",
    "    return np.array(item_similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now please call the function for the <b>whole</b> _interaction_matrix_test and the vector of the item with the <b>id 0</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.02083333 0.01030928 0.03529412 0.01449275 0.05555556\n",
      " 0.04347826 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.04545455 0.\n",
      " 0.         0.04545455 0.11764706 0.05882353 0.05882353 0.02150538\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.01898734 0.         0.         0.04545455 0.\n",
      " 0.         0.         0.         0.01265823 0.         0.\n",
      " 0.         0.         0.0625     0.         0.         0.05\n",
      " 0.05555556 0.05555556 0.08695652 0.05769231 0.0625     0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.07142857 0.         0.         0.\n",
      " 0.0625     0.01315789 0.0625     0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.04       0.         0.         0.         0.         0.03174603\n",
      " 0.         0.         0.01234568 0.         0.02040816 0.\n",
      " 0.         0.04545455 0.         0.00694444 0.02380952 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.02816901 0.         0.         0.02040816 0.02631579 0.\n",
      " 0.         0.         0.         0.03703704 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.01960784\n",
      " 0.         0.         0.03030303 0.01886792 0.         0.\n",
      " 0.         0.         0.         0.01612903 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.00740741 0.         0.         0.         0.\n",
      " 0.02325581 0.04166667 0.04761905 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.01030928\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.03225806 0.         0.         0.         0.02380952 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01204819 0.         0.         0.\n",
      " 0.         0.         0.         0.0212766  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.02702703\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.01639344 0.02857143 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.025      0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.04761905 0.\n",
      " 0.04166667 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.05882353 0.         0.         0.04347826 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.03571429 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.04347826 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.05882353\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# here we pass your jaccard_score function as \"similarity_measure\" parameter\n",
    "item_sims = calculate_sim_scores(similarity_measure=jaccard_score, inter=_interaction_matrix, target_vec=_interaction_matrix[:, 0])\n",
    "\n",
    "print(item_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert item_sims is not None, \"item_sims should not be None.\"\n",
    "assert type(item_sims) == np.ndarray, \"types are not correct.\"\n",
    "assert len(item_sims) == 412, \"length is not correct.\"\n",
    "assert item_sims[0] == 1, \"Item at the index 0 should have sim of 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>TASK 2/3</font>: Estimate user-item score (3 points)\n",
    "\n",
    "Write a function that takes a full interaction matrix as an input, as well as user id, item id and *n* -- algorithm's hyperparameter, number of neighbors to be considered while calculating the score.\n",
    "\n",
    "The expected output is a single number between 0 and 1 - the predicted score.\n",
    "\n",
    "Refer to the slides and the recording. Follow the algorithm:\n",
    "* take items consumed by the user\n",
    "* calculate the similarities between them and the target item (**exclude the target user from consideration** when calculating the similarities!)\n",
    "* return **average** of top **n** with the highest similarity scores\n",
    "\n",
    "<b>Tip:</b> Copy the interaction matrix before using it.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_item_score(sim_scores_calculator: Callable[[Callable, np.ndarray, np.ndarray], np.ndarray],\n",
    "                        inter: np.ndarray,\n",
    "                        target_user: int,\n",
    "                        target_item: int,\n",
    "                        n: int = 2) -> float:\n",
    "    \"\"\"\n",
    "    sim_scores_calculator: Callable - function that calculates similarities, using calculate_sim_scores\n",
    "                                      from above, already defined in the next cell\n",
    "    inter: np.ndarray - interaction matrix\n",
    "    target_user: target user id\n",
    "    target_item: int - target item id\n",
    "    n: int - n closest neighbors to consider for the score prediction\n",
    "    \n",
    "    returns: float - mean of similarity scores = user-item 'fitness' score\n",
    "    \"\"\"\n",
    "\n",
    "    # copy the inter. matrix\n",
    "    inter_matrix_copy = np.copy(inter[:, target_item])\n",
    "\n",
    "    # find the items consumed by the user\n",
    "    consumed_items = np.where(inter[target_user] > 0)[0]\n",
    "\n",
    "    # exclude the target user\n",
    "    inter_matrix_copy[target_user] = 0\n",
    "\n",
    "    # find the sim. between the target and the rest\n",
    "    item_similarities = sim_scores_calculator(inter[:, consumed_items], inter_matrix_copy)\n",
    "\n",
    "    # sort the sim. and take the top_n\n",
    "    top_n = sorted(item_similarities, reverse=True)[:n]\n",
    "\n",
    "    # find the mean of top_n\n",
    "    item_similarities_mean = np.mean(top_n)\n",
    "\n",
    "    return item_similarities_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, call your function for <b>user 0</b> and <b>item 0</b> and <b> n = 10</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1358018207282913\n"
     ]
    }
   ],
   "source": [
    "# you need to pass a \"sim_scores_calculator\" function into the \"get_user_item_score\" function,\n",
    "# but \"calculate_sim_scores\" also takes a similarity measure function as parameter.\n",
    "# The similarity measure is not necessarily present inside the \"get_user_item_score\" function\n",
    "# Ideally you want to provide the similarity measure together with the \"calculate_sim_scores\" function\n",
    "\n",
    "# The following line of code is one possible way to \"bind\" parameters to a function: you can now use the \"sim_score_calc\" function as parameter,\n",
    "# which will always use your \"jaccard_score\" function as first parameter for \"calculate_sim_scores\" and passes through the other parameters\n",
    "# This procedure is a way to keep your functions generic, you can now simply change your similarity measure via the\n",
    "# function calls without needing to change the function bodies themselves\n",
    "#\n",
    "# Another advantage for you is that when we test your solution, we are going to pass our own implementations into your functions\n",
    "# That means if you made a mistake in Task 1, you will still be able to get full points for consequent tasks if you did everything else correctly\n",
    "# So make sure that your functions work independently of your other implemented functions by using the code we provide in this cell\n",
    "\n",
    "def sim_score_calc(inter, target_vec): return calculate_sim_scores(jaccard_score, inter, target_vec)\n",
    "\n",
    "item_sim = get_user_item_score(sim_score_calc, _interaction_matrix, 0, 0, 10)\n",
    "\n",
    "print(item_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert item_sim is not None, \"item sim should have a value.\"\n",
    "assert item_sim <= 1 and item_sim >= 0, \"value of item sim is not valid.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>TASK 3/3</font>: Recommender (4 points)\n",
    "\n",
    "Implement the recommender function for the scoring algorithm you implemented above.\n",
    "The function takes user_item_scorer (wrapper function already defined below), a full interaction matrix, user id, top_k, hyperparameter **n** as an input. It returns two arrays:\n",
    "\n",
    "* top_k recommendations for the given user obtained considering **n** neighbors for score prediction\n",
    "* the corresponding user-item similarity scores\n",
    "\n",
    "Make sure you recommend items the user **hasn't seen** before! Try optimizing your implementation so that the runs take seconds rather than minutes.\n",
    "\n",
    "Please don't change the \"interface\" of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recTopK(user_item_scorer: Callable[[Callable, np.ndarray, int, int], float],\n",
    "            inter_matr: np.ndarray,\n",
    "            user: int,\n",
    "            top_k: int,\n",
    "            n: int) -> (np.ndarray, np.ndarray):\n",
    "    '''\n",
    "    user_item_scorer: Callable - wrapper function that calculates user-item score, using get_user_item_score function\n",
    "                                 from above, already defined in the next cell\n",
    "    inter_matr: np.ndarray - interaction matrix\n",
    "    user: int -  user_id\n",
    "    top_k: int - expected length of the resulting list\n",
    "    n: int - number of neighbors to consider\n",
    "    \n",
    "    returns - array of recommendations (sorted in the order of descending scores) & array of corresponding scores\n",
    "    '''\n",
    "\n",
    "    # define top_rec and scores\n",
    "    top_rec = []\n",
    "    scores = []\n",
    "\n",
    "    # iterate all items\n",
    "    for item in range(inter_matr.shape[1]):\n",
    "        if inter_matr[user, item] == 0:\n",
    "            score = user_item_scorer(inter_matr, user, item, n)\n",
    "            top_rec.append(item)\n",
    "            scores.append(score)\n",
    "\n",
    "    # convert to array and sort the rec. by score\n",
    "    top_rec = np.array(top_rec)\n",
    "    scores = np.array(scores)\n",
    "\n",
    "    # find the top_k\n",
    "    top_idx = np.argsort(scores)[-top_k:]\n",
    "    sorted_idx = top_idx[np.argsort(scores[top_idx])[::-1]]\n",
    "    top_rec = top_rec[sorted_idx]\n",
    "    scores = scores[sorted_idx]\n",
    "\n",
    "    return np.array(top_rec), np.array(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets use these scoring functions and get the <b>top 10</b> recommendations for <b>user 0</b> with <b>n = 15</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see Task 2 for an explanation of the following function definition\n",
    "def user_item_scorer(inter, target_user, target_item, n): return get_user_item_score(sim_score_calc, inter,\n",
    "                                                                                     target_user, target_item, n)\n",
    "\n",
    "rec_item_cf, scores_item_cf = recTopK(user_item_scorer, _interaction_matrix, 0, 10, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations with Item CF:  [117  51  12  43 129  56  30 167  98   8]\n",
      "With Scores:  [0.05700778 0.05121532 0.05023276 0.04848317 0.04670654 0.04642857\n",
      " 0.04491342 0.04259023 0.03993695 0.03945571]\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Recommendations with Item CF: \", rec_item_cf)\n",
    "print(\"With Scores: \", scores_item_cf)\n",
    "print(\"-\" * 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert rec_item_cf is not None, \"Recommendations should not be None.\"\n",
    "assert type(rec_item_cf) == np.ndarray, \"Types should be np.ndarray.\"\n",
    "assert len(rec_item_cf) == 10, \"10 recommendations should be returned.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert scores_item_cf is not None, \"Scores should not be None.\"\n",
    "assert type(scores_item_cf) == np.ndarray, \"Types should be np.ndarray.\"\n",
    "assert len(scores_item_cf) == 10, \"10 recommendations should be returned.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this cell the way it is, please."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
